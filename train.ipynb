{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 8139557,
     "sourceType": "datasetVersion",
     "datasetId": 4812216
    }
   ],
   "dockerImageVersionId": 30683,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!mkdir Dataset\n",
    "!tar --extract --file /kaggle/input/mapbox/DataSet.tgz\n",
    "!mv Mapbox Dataset"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -U wandb \n",
    "!pip install -U ipywidgets\n",
    "!pip install ipysheet\n",
    "!pip install pytorch-lightning\n",
    "!pip install lightning\n",
    "import wandb\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "wandb.login(key=\"Ваш ключ WandB\", relogin=True)\n",
    "run = wandb.init(project=\"Upscaler\", name = \"Upscaler Base\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import gc\n",
    "\n",
    "class Upscaler(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super(Upscaler, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Progressive Decoder\n",
    "        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=2.0)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2.0)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.upsample1(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.upsample2(x)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.conv6(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def train_model(model, train_loader, val_loader, num_epochs, device):\n",
    "\n",
    "        # Move the model to the device\n",
    "        model.load_state_dict(torch.load(\"/kaggle/working/modelDict.pt\"))\n",
    "        model.to(device)\n",
    "\n",
    "        # Define the loss function and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            for high_res, trash in train_loader:\n",
    "                print(high_res.size())\n",
    "\n",
    "                low_res = model.getLowRes(high_res)\n",
    "\n",
    "                high_res = high_res.to(device)\n",
    "                low_res = low_res.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                output = model(low_res)\n",
    "                loss = criterion(output, high_res)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for high_res, trash in val_loader:\n",
    "                    low_res = model.getLowRes(high_res)\n",
    "\n",
    "                    high_res = high_res.to(device)\n",
    "                    low_res = low_res.to(device)\n",
    "\n",
    "                    output = model(low_res)\n",
    "                    val_loss += criterion(output, high_res).item()\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            # Print the progress\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "            # Save a sample output image\n",
    "            torch.save(model.state_dict(), \"modelDict.pt\")\n",
    "            sample_output = model(low_res[:1])\n",
    "            save_image(sample_output, f'sample_output_epoch_{epoch + 1}.png')\n",
    "\n",
    "        return model\n",
    "\n",
    "    def getLowRes(self, high_res):\n",
    "        img_array = high_res.numpy()\n",
    "        img_array = np.transpose(img_array, (0, 2, 3, 1))\n",
    "        resized_images = []\n",
    "        for img in img_array:\n",
    "            resized_img = cv2.resize(img, (400, 400))  # Resize to (64, 64)\n",
    "            resized_images.append(resized_img)\n",
    "        resized_images = np.array(resized_images)\n",
    "        resized_tensor = torch.from_numpy(resized_images)\n",
    "        # Transpose back to tensor shape (32, 3, 64, 64)\n",
    "        return resized_tensor.permute(0, 3, 1, 2)\n",
    "\n",
    "    def UpcsalerInference(self):\n",
    "        model = Upscaler()\n",
    "        model.load_state_dict(torch.load('upscaler_model.pth'))\n",
    "        model.eval()\n",
    "\n",
    "        # Define the preprocessing transformations\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        # Open the input low-resolution image\n",
    "        input_image = Image.open('input_image.jpg')\n",
    "\n",
    "        # Preprocess the input image\n",
    "        input_tensor = preprocess(input_image).unsqueeze(0)\n",
    "\n",
    "        # Upscale the input image\n",
    "        with torch.no_grad():\n",
    "            output_tensor = model(input_tensor)\n",
    "\n",
    "        # Postprocess the output tensor\n",
    "        output_tensor = output_tensor.squeeze(0)\n",
    "        output_tensor = output_tensor.permute(1, 2, 0)  # CHW to HWC\n",
    "        output_image = transforms.ToPILImage()(output_tensor)\n",
    "\n",
    "        # Save the upscaled image\n",
    "        output_image.save('upscaled_image.jpg')\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.utils.data\n",
    "\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# Example usage\n",
    "high_res_folder = 'Dataset'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((800, 800)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "high_res_dataset = ImageFolder(high_res_folder, transform=transform)\n",
    "\n",
    "generator1 = torch.Generator().manual_seed(21)\n",
    "\n",
    "train_set, val_set, other = torch.utils.data.random_split(high_res_dataset, [0.5, 0.1, 0.4], generator1)\n",
    "train_loader = DataLoader(train_set, batch_size = 8, shuffle=True, )\n",
    "val_loader = DataLoader(val_set, batch_size=8, shuffle=True,)\n",
    "\n",
    "del high_res_dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Upscaler((400,400))\n",
    "model = nn.DataParallel(model)\n",
    "model.module.train_model( train_loader=train_loader, val_loader=val_loader, num_epochs=5,\n",
    "                  device=device)\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PL"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Путь к папке с изображениями\n",
    "image_folder = '/kaggle/working/Dataset/Mapbox'\n",
    "\n",
    "# Пороговое значение для удаления изображений\n",
    "threshold = 20\n",
    "for filename in os.listdir(image_folder):\n",
    "    img_path = os.path.join(image_folder, filename)\n",
    "    \n",
    "    # Проверяем, является ли файл изображением\n",
    "    if img_path.endswith(('.jpg', '.png', '.bmp')):\n",
    "        \n",
    "        # Загружаем изображение\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        # Вычисляем среднее значение по каналам цвета\n",
    "        mean = cv2.mean(img)\n",
    "        \n",
    "        # Если все средние значения близки друг к другу (в пределах порогового значения),\n",
    "        # то изображение считается однотонным\n",
    "        if abs(mean[0] - mean[1]) < threshold and abs(mean[1] - mean[2]) < threshold and abs(mean[0] - mean[2]) < threshold:\n",
    "            # Удаляем изображение\n",
    "            os.remove(img_path)\n",
    "            print(f'Удалено изображение: {filename}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-23T22:21:23.772743Z",
     "iopub.execute_input": "2024-04-23T22:21:23.773149Z",
     "iopub.status.idle": "2024-04-23T22:25:45.337320Z",
     "shell.execute_reply.started": "2024-04-23T22:21:23.773117Z",
     "shell.execute_reply": "2024-04-23T22:25:45.335831Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": "Удалено изображение: 5013.png\nУдалено изображение: 2284.png\nУдалено изображение: 5283.png\nУдалено изображение: 9940.png\nУдалено изображение: 4048.png\nУдалено изображение: 3066.png\nУдалено изображение: 9689.png\nУдалено изображение: 3965.png\nУдалено изображение: 2104.png\nУдалено изображение: 4572.png\nУдалено изображение: 3251.png\nУдалено изображение: 9303.png\nУдалено изображение: 7087.png\nУдалено изображение: 7440.png\nУдалено изображение: 6071.png\nУдалено изображение: 9781.png\nУдалено изображение: 9728.png\nУдалено изображение: 3354.png\nУдалено изображение: 5186.png\nУдалено изображение: 1298.png\nУдалено изображение: 55.png\nУдалено изображение: 9469.png\nУдалено изображение: 1620.png\nУдалено изображение: 2193.png\nУдалено изображение: 3541.png\nУдалено изображение: 2081.png\nУдалено изображение: 5156.png\nУдалено изображение: 1678.png\nУдалено изображение: 9795.png\nУдалено изображение: 9123.png\nУдалено изображение: 7612.png\nУдалено изображение: 8716.png\nУдалено изображение: 3315.png\nУдалено изображение: 7523.png\nУдалено изображение: 4195.png\nУдалено изображение: 9522.png\nУдалено изображение: 1037.png\nУдалено изображение: 144.png\nУдалено изображение: 8247.png\nУдалено изображение: 6350.png\nУдалено изображение: 7455.png\nУдалено изображение: 5902.png\nУдалено изображение: 9058.png\nУдалено изображение: 4560.png\nУдалено изображение: 6682.png\nУдалено изображение: 6819.png\nУдалено изображение: 1935.png\nУдалено изображение: 8158.png\nУдалено изображение: 7464.png\nУдалено изображение: 2183.png\nУдалено изображение: 5197.png\nУдалено изображение: 4301.png\nУдалено изображение: 6067.png\nУдалено изображение: 8613.png\nУдалено изображение: 7234.png\nУдалено изображение: 7362.png\nУдалено изображение: 5415.png\nУдалено изображение: 3582.png\nУдалено изображение: 5622.png\nУдалено изображение: 8313.png\nУдалено изображение: 9909.png\nУдалено изображение: 2224.png\nУдалено изображение: 9036.png\nУдалено изображение: 5110.png\nУдалено изображение: 2932.png\nУдалено изображение: 1170.png\nУдалено изображение: 3057.png\nУдалено изображение: 9475.png\nУдалено изображение: 3750.png\nУдалено изображение: 9282.png\nУдалено изображение: 4167.png\nУдалено изображение: 7177.png\nУдалено изображение: 7760.png\nУдалено изображение: 3314.png\nУдалено изображение: 4223.png\nУдалено изображение: 5507.png\nУдалено изображение: 5428.png\nУдалено изображение: 873.png\nУдалено изображение: 1331.png\nУдалено изображение: 2243.png\nУдалено изображение: 3904.png\nУдалено изображение: 5325.png\nУдалено изображение: 8507.png\nУдалено изображение: 9536.png\nУдалено изображение: 1812.png\nУдалено изображение: 4575.png\nУдалено изображение: 6257.png\nУдалено изображение: 2175.png\nУдалено изображение: 5133.png\nУдалено изображение: 4009.png\nУдалено изображение: 8251.png\nУдалено изображение: 4125.png\nУдалено изображение: 4337.png\nУдалено изображение: 7056.png\nУдалено изображение: 2158.png\nУдалено изображение: 9051.png\nУдалено изображение: 8877.png\nУдалено изображение: 3645.png\nУдалено изображение: 1686.png\nУдалено изображение: 462.png\nУдалено изображение: 4392.png\nУдалено изображение: 9956.png\nУдалено изображение: 1429.png\nУдалено изображение: 6627.png\nУдалено изображение: 1651.png\nУдалено изображение: 2145.png\nУдалено изображение: 5033.png\nУдалено изображение: 9250.png\nУдалено изображение: 9787.png\nУдалено изображение: 8758.png\nУдалено изображение: 7820.png\nУдалено изображение: 2609.png\nУдалено изображение: 7626.png\nУдалено изображение: 5647.png\nУдалено изображение: 1642.png\nУдалено изображение: 1914.png\nУдалено изображение: 1663.png\nУдалено изображение: 2071.png\nУдалено изображение: 4354.png\nУдалено изображение: 3740.png\nУдалено изображение: 720.png\nУдалено изображение: 4052.png\nУдалено изображение: 6396.png\nУдалено изображение: 8212.png\nУдалено изображение: 8518.png\nУдалено изображение: 3723.png\nУдалено изображение: 7906.png\nУдалено изображение: 3465.png\nУдалено изображение: 6676.png\nУдалено изображение: 9138.png\nУдалено изображение: 2437.png\nУдалено изображение: 4528.png\nУдалено изображение: 7875.png\nУдалено изображение: 7202.png\nУдалено изображение: 9225.png\nУдалено изображение: 6413.png\nУдалено изображение: 7750.png\nУдалено изображение: 382.png\nУдалено изображение: 4555.png\nУдалено изображение: 6148.png\nУдалено изображение: 8333.png\nУдалено изображение: 840.png\nУдалено изображение: 2482.png\nУдалено изображение: 2505.png\nУдалено изображение: 6539.png\nУдалено изображение: 3963.png\nУдалено изображение: 7772.png\nУдалено изображение: 9774.png\nУдалено изображение: 6786.png\nУдалено изображение: 1809.png\nУдалено изображение: 2904.png\nУдалено изображение: 7873.png\nУдалено изображение: 1576.png\nУдалено изображение: 580.png\nУдалено изображение: 9763.png\nУдалено изображение: 1492.png\nУдалено изображение: 8713.png\nУдалено изображение: 8867.png\nУдалено изображение: 3150.png\nУдалено изображение: 517.png\nУдалено изображение: 8775.png\nУдалено изображение: 640.png\nУдалено изображение: 847.png\nУдалено изображение: 2004.png\nУдалено изображение: 30.png\nУдалено изображение: 1261.png\nУдалено изображение: 2368.png\nУдалено изображение: 6665.png\nУдалено изображение: 1689.png\nУдалено изображение: 9169.png\nУдалено изображение: 948.png\nУдалено изображение: 6433.png\nУдалено изображение: 2980.png\nУдалено изображение: 2496.png\nУдалено изображение: 1579.png\nУдалено изображение: 1285.png\nУдалено изображение: 2270.png\nУдалено изображение: 278.png\nУдалено изображение: 3870.png\nУдалено изображение: 7394.png\nУдалено изображение: 7126.png\nУдалено изображение: 4426.png\nУдалено изображение: 4343.png\nУдалено изображение: 1908.png\nУдалено изображение: 7505.png\nУдалено изображение: 3003.png\nУдалено изображение: 3199.png\nУдалено изображение: 5193.png\nУдалено изображение: 8942.png\nУдалено изображение: 1321.png\nУдалено изображение: 7049.png\nУдалено изображение: 9170.png\nУдалено изображение: 2234.png\nУдалено изображение: 7360.png\nУдалено изображение: 8690.png\nУдалено изображение: 8669.png\nУдалено изображение: 3457.png\nУдалено изображение: 8571.png\nУдалено изображение: 902.png\nУдалено изображение: 5978.png\nУдалено изображение: 8767.png\nУдалено изображение: 9220.png\nУдалено изображение: 5360.png\nУдалено изображение: 6089.png\nУдалено изображение: 7638.png\nУдалено изображение: 2615.png\nУдалено изображение: 8687.png\nУдалено изображение: 1740.png\nУдалено изображение: 7729.png\nУдалено изображение: 167.png\nУдалено изображение: 8338.png\nУдалено изображение: 5178.png\nУдалено изображение: 229.png\nУдалено изображение: 9803.png\nУдалено изображение: 9718.png\nУдалено изображение: 3700.png\nУдалено изображение: 3734.png\nУдалено изображение: 1519.png\nУдалено изображение: 6241.png\nУдалено изображение: 3308.png\nУдалено изображение: 4803.png\nУдалено изображение: 1082.png\nУдалено изображение: 9939.png\nУдалено изображение: 9753.png\nУдалено изображение: 350.png\nУдалено изображение: 7149.png\nУдалено изображение: 1227.png\nУдалено изображение: 2323.png\nУдалено изображение: 2242.png\nУдалено изображение: 6952.png\nУдалено изображение: 3596.png\nУдалено изображение: 7976.png\nУдалено изображение: 3982.png\nУдалено изображение: 1457.png\nУдалено изображение: 9481.png\nУдалено изображение: 5095.png\nУдалено изображение: 3746.png\nУдалено изображение: 7257.png\nУдалено изображение: 6781.png\nУдалено изображение: 610.png\nУдалено изображение: 3212.png\nУдалено изображение: 2254.png\nУдалено изображение: 9082.png\nУдалено изображение: 348.png\nУдалено изображение: 6625.png\nУдалено изображение: 3422.png\nУдалено изображение: 1090.png\nУдалено изображение: 4853.png\nУдалено изображение: 4546.png\nУдалено изображение: 8207.png\nУдалено изображение: 6281.png\nУдалено изображение: 658.png\nУдалено изображение: 3864.png\nУдалено изображение: 7196.png\nУдалено изображение: 3719.png\nУдалено изображение: 6860.png\nУдалено изображение: 8206.png\nУдалено изображение: 7975.png\nУдалено изображение: 3781.png\nУдалено изображение: 5914.png\nУдалено изображение: 4984.png\nУдалено изображение: 4348.png\nУдалено изображение: 9543.png\nУдалено изображение: 9274.png\nУдалено изображение: 226.png\nУдалено изображение: 1072.png\nУдалено изображение: 1116.png\nУдалено изображение: 7993.png\nУдалено изображение: 4648.png\nУдалено изображение: 3657.png\nУдалено изображение: 2186.png\nУдалено изображение: 9436.png\nУдалено изображение: 900.png\nУдалено изображение: 2643.png\nУдалено изображение: 3166.png\nУдалено изображение: 2093.png\nУдалено изображение: 7005.png\nУдалено изображение: 9244.png\nУдалено изображение: 9443.png\nУдалено изображение: 3405.png\nУдалено изображение: 9113.png\nУдалено изображение: 9801.png\nУдалено изображение: 7384.png\nУдалено изображение: 9474.png\nУдалено изображение: 3980.png\nУдалено изображение: 782.png\nУдалено изображение: 4704.png\nУдалено изображение: 7275.png\nУдалено изображение: 3043.png\nУдалено изображение: 1361.png\nУдалено изображение: 7217.png\nУдалено изображение: 2601.png\nУдалено изображение: 574.png\nУдалено изображение: 9577.png\nУдалено изображение: 2674.png\nУдалено изображение: 606.png\nУдалено изображение: 3450.png\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "wandb.login(key=\"504d320dca3edf2d54e8a21e0c24f4251cd7e0c0\", relogin=True)\n",
    "run = wandb.init(project=\"Upscaler\", name = \"Upscaler Base\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-23T21:36:50.940434Z",
     "iopub.execute_input": "2024-04-23T21:36:50.941306Z",
     "iopub.status.idle": "2024-04-23T21:37:15.888961Z",
     "shell.execute_reply.started": "2024-04-23T21:36:50.941269Z",
     "shell.execute_reply": "2024-04-23T21:37:15.888047Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mkamenevv2\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113012388889527, max=1.0…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f45bce66c0f3443a959e88c7a40c5c47"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.6"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20240423_213656-bkhl3ce1</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/kamenevv2/Upscaler/runs/bkhl3ce1' target=\"_blank\">Upscaler Base</a></strong> to <a href='https://wandb.ai/kamenevv2/Upscaler' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/kamenevv2/Upscaler' target=\"_blank\">https://wandb.ai/kamenevv2/Upscaler</a>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/kamenevv2/Upscaler/runs/bkhl3ce1' target=\"_blank\">https://wandb.ai/kamenevv2/Upscaler/runs/bkhl3ce1</a>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import pytorch_lightning as pl\n",
    "import gc\n",
    "\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "\n",
    "class Upscaler(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super(Upscaler, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Progressive Decoder\n",
    "        self.upsample1 = nn.UpsamplingNearest2d(scale_factor=2.0)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.upsample2 = nn.UpsamplingNearest2d(scale_factor=2.0)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.upsample1(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.upsample2(x)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.conv6(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        print(batch_idx)\n",
    "        high_res, _ = batch\n",
    "        low_res = self.getLowRes(high_res)\n",
    "        low_res = low_res.to(device='cuda')\n",
    "\n",
    "        output = self(low_res)\n",
    "        loss = nn.MSELoss()(output, high_res)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        high_res, _ = batch\n",
    "        low_res = self.getLowRes(high_res)\n",
    "        low_res = low_res.to(device='cuda')\n",
    "        high_res = high_res.to(device='cuda')\n",
    "        \n",
    "        output = self(low_res)\n",
    "        loss = nn.MSELoss()(output, high_res)\n",
    "        \n",
    "        ssim = StructuralSimilarityIndexMeasure(data_range=1.0).to(device='cuda')\n",
    "        psnr = PeakSignalNoiseRatio().to(device='cuda')\n",
    "        \n",
    "        metricPsnr = psnr(output, high_res)\n",
    "        metricSsim = ssim(output, high_res)\n",
    "        \n",
    "        self.log('val_loss', loss, sync_dist=True)\n",
    "        wandb.log({\"train/loss\": loss})\n",
    "        wandb.log({\"train/psnr\": metricPsnr})\n",
    "        wandb.log({\"train/ssim\": metricSsim})\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "    def getLowRes(self, high_res):\n",
    "        img_array = high_res.cpu().numpy()\n",
    "        img_array = np.transpose(img_array, (0, 2, 3, 1))\n",
    "        resized_images = []\n",
    "        for img in img_array:\n",
    "            resized_img = cv2.resize(img, (400, 400))  # Resize to (64, 64)\n",
    "            resized_images.append(resized_img)\n",
    "        resized_images = np.array(resized_images)\n",
    "        resized_tensor = torch.from_numpy(resized_images)\n",
    "        # Transpose back to tensor shape (32, 3, 64, 64)\n",
    "        return resized_tensor.permute(0, 3, 1, 2)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-23T22:44:44.147005Z",
     "iopub.execute_input": "2024-04-23T22:44:44.147401Z",
     "iopub.status.idle": "2024-04-23T22:44:44.171006Z",
     "shell.execute_reply.started": "2024-04-23T22:44:44.147371Z",
     "shell.execute_reply": "2024-04-23T22:44:44.169771Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.utils.data\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "gc.collect()\n",
    "# Example usage\n",
    "high_res_folder = 'Dataset'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((800, 800)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "high_res_dataset = ImageFolder(high_res_folder, transform=transform)\n",
    "\n",
    "generator1 = torch.Generator().manual_seed(21)\n",
    "\n",
    "train_set, val_set, other = torch.utils.data.random_split(high_res_dataset, [0.6, 0.1, 0.3], generator1)\n",
    "train_loader = DataLoader(train_set, batch_size = 12, shuffle=False,  num_workers=3)\n",
    "val_loader = DataLoader(val_set, batch_size=12, shuffle=False, num_workers=3)\n",
    "\n",
    "del high_res_dataset\n",
    "del other\n",
    "\n",
    "\n",
    "model = Upscaler((400,400))\n",
    "wandb_logger = WandbLogger(project=\"Upscaler\", log_model=True)\n",
    "\n",
    "# Создание объекта Trainer и обучение модели\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"gpu\", devices=2, strategy=\"ddp_notebook\", logger=wandb_logger)\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-23T22:44:46.060418Z",
     "iopub.execute_input": "2024-04-23T22:44:46.061096Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "INFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: IPU available: False, using: 0 IPUs\nINFO: HPU available: False, using: 0 HPUs\nINFO: ----------------------------------------------------------------------------------------------------\ndistributed_backend=nccl\nAll distributed processes registered. Starting with 2 processes\n----------------------------------------------------------------------------------------------------\n\n/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory ./Upscaler/bkhl3ce1/checkpoints exists and is not empty.\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0991da9471042f586e0e3c6f3ac053b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7606dd30f4d04346894e8feeb23b2a48"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "0\n0\n1\n1\n22\n\n33\n\n4\n4\n55\n\n6\n6\n77\n\n88\n\n9\n9\n1010\n\n11\n11\n1212\n\n1313\n\n14\n14\n1515\n\n16\n16\n1717\n\n1818\n\n19\n19\n20\n20\n2121\n\n2222\n\n2323\n\n2424\n\n25\n25\n2626\n\n2727\n\n28\n28\n2929\n\n3030\n\n3131\n\n32\n32\n33\n33\n3434\n\n3535\n\n36\n36\n3737\n\n3838\n\n3939\n\n40\n40\n41\n41\n4242\n\n4343\n\n4444\n\n4545\n\n4646\n\n4747\n\n4848\n\n4949\n\n5050\n\n5151\n\n5252\n\n5353\n\n54\n54\n5555\n\n5656\n\n57\n57\n5858\n\n5959\n\n6060\n\n6161\n\n6262\n\n6363\n\n6464\n\n6565\n\n6666\n\n6767\n\n6868\n\n6969\n\n7070\n\n7171\n\n7272\n\n7373\n\n7474\n\n75\n75\n7676\n\n7777\n\n7878\n\n7979\n\n8080\n\n8181\n\n8282\n\n83\n83\n84\n84\n8585\n\n8686\n\n8787\n\n8888\n\n8989\n\n9090\n\n9191\n\n9292\n\n9393\n\n9494\n\n9595\n\n9696\n\n9797\n\n9898\n\n9999\n\n100\n100\n101\n101\n102\n102\n103103\n\n104104\n\n105105\n\n106106\n\n107107\n\n108108\n\n109109\n\n110110\n\n111111\n\n112112\n\n113\n113\n114114\n\n115115\n\n116116\n\n117117\n\n118118\n\n119\n119\n120\n120\n121121\n\n122122\n\n123123\n\n124124\n\n125125\n\n126126\n\n127127\n\n128128\n\n129129\n\n130130\n\n131131\n\n132132\n\n133133\n\n134134\n\n135135\n\n136136\n\n137137\n\n138138\n\n139139\n\n140140\n\n141141\n\n142\n142\n143143\n\n144144\n\n145145\n\n146146\n\n147147\n\n148148\n\n149149\n\n150150\n\n151151\n\n152152\n\n153153\n\n154154\n\n155\n155\n156156\n\n157157\n\n158158\n\n159159\n\n160160\n\n161161\n\n162162\n\n163\n163\n164164\n\n165165\n\n166166\n\n167167\n\n168168\n\n169169\n\n170170\n\n171171\n\n172172\n\n173173\n\n174174\n\n175175\n\n176176\n\n177177\n\n178\n178\n179179\n\n180180\n\n181181\n\n182182\n\n183183\n\n184\n184\n185185\n\n186186\n\n187187\n\n188188\n\n189189\n\n190\n190\n191\n191\n192192\n\n193193\n\n194194\n\n195195\n\n196196\n\n197197\n\n198198\n\n199\n199\n200200\n\n201\n201\n202202\n\n203203\n\n204204\n\n205205\n\n206206\n\n207207\n\n208208\n\n209209\n\n210210\n\n211211\n\n212212\n\n213213\n\n214214\n\n215215\n\n216216\n\n217217\n\n218\n218\n219219\n\n220220\n\n221221\n\n222222\n\n223223\n\n224224\n\n225225\n\n226\n226\n227\n227\n228228\n\n229229\n\n230230\n\n231231\n\n232232\n\n233233\n\n234\n234\n235235\n\n236236\n\n237237\n\n238238\n\n239239\n\n240240\n\n241241\n\n242242\n\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c64e074743cc42bcab980404d50bb2f7"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "0\n0\n1\n1\n2\n2\n33\n\n44\n\n55\n\n66\n\n7\n7\n8\n8\n99\n\n1010\n\n1111\n\n1212\n\n1313\n\n1414\n\n1515\n\n1616\n\n1717\n\n1818\n\n1919\n\n20\n20\n2121\n\n22\n22\n2323\n\n2424\n\n2525\n\n2626\n\n2727\n\n2828\n\n2929\n\n3030\n\n3131\n\n32\n32\n3333\n\n3434\n\n3535\n\n3636\n\n3737\n\n3838\n\n3939\n\n4040\n\n41\n41\n4242\n\n4343\n\n4444\n\n4545\n\n4646\n\n4747\n\n4848\n\n4949\n\n5050\n\n5151\n\n5252\n\n5353\n\n5454\n\n5555\n\n5656\n\n5757\n\n5858\n\n5959\n\n6060\n\n6161\n\n6262\n\n6363\n\n6464\n\n6565\n\n66\n66\n6767\n\n6868\n\n6969\n\n7070\n\n7171\n\n7272\n\n7373\n\n7474\n\n7575\n\n7676\n\n7777\n\n7878\n\n7979\n\n8080\n\n81\n81\n8282\n\n8383\n\n8484\n\n8585\n\n8686\n\n8787\n\n8888\n\n8989\n\n9090\n\n9191\n\n9292\n\n93\n93\n9494\n\n9595\n\n9696\n\n9797\n\n9898\n\n9999\n\n100\n100\n101\n101\n102102\n\n103103\n\n104104\n\n105105\n\n106106\n\n107\n107\n108108\n\n109109\n\n110110\n\n111111\n\n112\n112\n113113\n\n114114\n\n115115\n\n116116\n\n117117\n\n118118\n\n119119\n\n120\n120\n121121\n\n122122\n\n123123\n\n124124\n\n125\n125\n126126\n\n127127\n\n128128\n\n129129\n\n130130\n\n131131\n\n132132\n\n133133\n\n134134\n\n135135\n\n136136\n\n137137\n\n138\n138\n139139\n\n140\n140\n141141\n\n142142\n\n143143\n\n144144\n\n145145\n\n146146\n\n147147\n\n148148\n\n149149\n\n150150\n\n151151\n\n152152\n\n153153\n\n154154\n\n155155\n\n156156\n\n157157\n\n158158\n\n159\n159\n160160\n\n161161\n\n162162\n\n163163\n\n164164\n\n165165\n\n166166\n\n167167\n\n168168\n\n169169\n\n170170\n\n171171\n\n172172\n\n173173\n\n174174\n\n175175\n\n176176\n\n177177\n\n178178\n\n179\n179\n180\n180\n181\n181\n182182\n\n183183\n\n184184\n\n185185\n\n186186\n\n187187\n\n188188\n\n189189\n\n190\n190\n191191\n\n192192\n\n193193\n\n194194\n\n195195\n\n196196\n\n197197\n\n198198\n\n199199\n\n200\n200\n201\n201\n202202\n\n203203\n\n204204\n\n205205\n\n206206\n\n207207\n\n208208\n\n209209\n\n210210\n\n211211\n\n212212\n\n213213\n\n214214\n\n215215\n\n216216\n\n217\n217\n218\n218\n219219\n\n220\n220\n221221\n\n222222\n\n223223\n\n224224\n\n225225\n\n226226\n\n227227\n\n228228\n\n229229\n\n230230\n\n231231\n\n232232\n\n233233\n\n234234\n\n235235\n\n236236\n\n237237\n\n238238\n\n239239\n\n240\n240\n241241\n\n242242\n\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d34723e97ada46aa85e10d6162ea60d8"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "0\n0\n1\n1\n22\n\n33\n\n44\n\n55\n\n66\n\n77\n\n88\n\n99\n\n1010\n\n11\n11\n1212\n\n1313\n\n1414\n\n1515\n\n1616\n\n1717\n\n1818\n\n1919\n\n2020\n\n2121\n\n2222\n\n2323\n\n2424\n\n2525\n\n2626\n\n2727\n\n28\n28\n2929\n\n3030\n\n3131\n\n3232\n\n3333\n\n34\n34\n3535\n\n3636\n\n3737\n\n3838\n\n3939\n\n4040\n\n4141\n\n4242\n\n4343\n\n4444\n\n4545\n\n4646\n\n4747\n\n4848\n\n4949\n\n5050\n\n5151\n\n5252\n\n5353\n\n5454\n\n5555\n\n56\n56\n5757\n\n5858\n\n5959\n\n6060\n\n6161\n\n6262\n\n6363\n\n6464\n\n65\n65\n6666\n\n6767\n\n6868\n\n6969\n\n7070\n\n7171\n\n7272\n\n7373\n\n74\n74\n7575\n\n7676\n\n7777\n\n7878\n\n7979\n\n8080\n\n8181\n\n8282\n\n8383\n\n8484\n\n8585\n\n8686\n\n8787\n\n8888\n\n8989\n\n9090\n\n9191\n\n9292\n\n9393\n\n9494\n\n9595\n\n9696\n\n9797\n\n9898\n\n9999\n\n100100\n\n101101\n\n102102\n\n103103\n\n104104\n\n105105\n\n106106\n\n107107\n\n108108\n\n109109\n\n110110\n\n111111\n\n112112\n\n113113\n\n114114\n\n115\n115\n116116\n\n117117\n\n118118\n\n119119\n\n120120\n\n121121\n\n122122\n\n123\n123\n124124\n\n125125\n\n126126\n\n127127\n\n128128\n\n129129\n\n130130\n\n131131\n\n132132\n\n133133\n\n134134\n\n135135\n\n136136\n\n137137\n\n138138\n\n139\n139\n140140\n\n141141\n\n142142\n\n143143\n\n144144\n\n145145\n\n146146\n\n147147\n\n148148\n\n149149\n\n150150\n\n151151\n\n152152\n\n153153\n\n154154\n\n155155\n\n156156\n\n157157\n\n158158\n\n159159\n\n160160\n\n161161\n\n162162\n\n163163\n\n164\n164\n165165\n\n166166\n\n167167\n\n168168\n\n169\n169\n170170\n\n171171\n\n172172\n\n173173\n\n174174\n\n175175\n\n176176\n\n177177\n\n178178\n\n179179\n\n180180\n\n181181\n\n182182\n\n183183\n\n184184\n\n185\n185\n186186\n\n187187\n\n188188\n\n189189\n\n190190\n\n191\n191\n192192\n\n193193\n\n194194\n\n195195\n\n196196\n\n197197\n\n198198\n\n199199\n\n200200\n\n201201\n\n202202\n\n203203\n\n204204\n\n205205\n\n206206\n\n207207\n\n208208\n\n209209\n\n210210\n\n211211\n\n212212\n\n213\n213\n214\n214\n215215\n\n216216\n\n217217\n\n218218\n\n219219\n\n220220\n\n221221\n\n222222\n\n223223\n\n224224\n\n225225\n\n226226\n\n227227\n\n228228\n\n229229\n\n230230\n\n231231\n\n232232\n\n233233\n\n234234\n\n235235\n\n236236\n\n237237\n\n238238\n\n239\n239\n240240\n\n241241\n\n242242\n\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c2f7b4020a442acab979b3c3f8cfe85"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "0\n0\n1\n1\n2\n2\n33\n\n44\n\n55\n\n66\n\n77\n\n88\n\n99\n\n1010\n\n1111\n\n1212\n\n1313\n\n1414\n\n1515\n\n1616\n\n1717\n\n1818\n\n1919\n\n2020\n\n2121\n\n2222\n\n2323\n\n2424\n\n2525\n\n2626\n\n27\n27\n28\n28\n2929\n\n3030\n\n3131\n\n3232\n\n3333\n\n34\n34\n3535\n\n3636\n\n37\n37\n3838\n\n3939\n\n4040\n\n41\n41\n4242\n\n4343\n\n4444\n\n4545\n\n4646\n\n4747\n\n4848\n\n4949\n\n5050\n\n5151\n\n5252\n\n5353\n\n5454\n\n5555\n\n5656\n\n5757\n\n5858\n\n5959\n\n6060\n\n6161\n\n6262\n\n6363\n\n6464\n\n6565\n\n66\n66\n67\n67\n6868\n\n6969\n\n7070\n\n7171\n\n72\n72\n7373\n\n7474\n\n7575\n\n7676\n\n7777\n\n7878\n\n79\n79\n8080\n\n8181\n\n8282\n\n83\n83\n8484\n\n8585\n\n86\n86\n87\n87\n8888\n\n8989\n\n9090\n\n9191\n\n9292\n\n9393\n\n9494\n\n9595\n\n9696\n\n9797\n\n9898\n\n9999\n\n100100\n\n101101\n\n102102\n\n103103\n\n104104\n\n105105\n\n106\n106\n107107\n\n108108\n\n109109\n\n110110\n\n111111\n\n112112\n\n113113\n\n114114\n\n115\n115\n116116\n\n117117\n\n118118\n\n119119\n\n120120\n\n121121\n\n122122\n\n123123\n\n124124\n\n125125\n\n126126\n\n127127\n\n128128\n\n129129\n\n130130\n\n131131\n\n132132\n\n133\n133\n134134\n\n135135\n\n136136\n\n137137\n\n138138\n\n139139\n\n140140\n\n141141\n\n142142\n\n143143\n\n144144\n\n145145\n\n146\n146\n147\n147\n148148\n\n149\n149\n150150\n\n151151\n\n152152\n\n153153\n\n154154\n\n155155\n\n156156\n\n157157\n\n158158\n\n159159\n\n160160\n\n161161\n\n162162\n\n163163\n\n164164\n\n165165\n\n166166\n\n167167\n\n168168\n\n169169\n\n170170\n\n171171\n\n172172\n\n173173\n\n174174\n\n175175\n\n176\n176\n177177\n\n178178\n\n179179\n\n180180\n\n181181\n\n182182\n\n183183\n\n184184\n\n185185\n\n186186\n\n187187\n\n188188\n\n189189\n\n190190\n\n191191\n\n192192\n\n193193\n\n194194\n\n195195\n\n196196\n\n197197\n\n198198\n\n199199\n\n200\n200\n201201\n\n202202\n\n203203\n\n204\n204\n205205\n\n206\n206\n207207\n\n208208\n\n209209\n\n210210\n\n211\n211\n212212\n\n213213\n\n214214\n\n215215\n\n216216\n\n217217\n\n218218\n\n219219\n\n220220\n\n221221\n\n222222\n\n223223\n\n224224\n\n225225\n\n226226\n\n227227\n\n228228\n\n229229\n\n230230\n\n231231\n\n232232\n\n233233\n\n234\n234\n235235\n\n236236\n\n237237\n\n238238\n\n239239\n\n240240\n\n241241\n\n242242\n\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0853dca251914d0c9b56596b092495c5"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "0\n0\n1\n1\n2\n2\n33\n\n4\n4\n55\n\n66\n\n77\n\n88\n\n99\n\n1010\n\n1111\n\n12\n12\n1313\n\n1414\n\n1515\n\n1616\n\n1717\n\n1818\n\n19\n19\n2020\n\n2121\n\n2222\n\n2323\n\n2424\n\n2525\n\n2626\n\n2727\n\n2828\n\n2929\n\n3030\n\n3131\n\n3232\n\n3333\n\n3434\n\n3535\n\n3636\n\n3737\n\n3838\n\n39\n39\n40\n40\n4141\n\n4242\n\n4343\n\n4444\n\n4545\n\n4646\n\n4747\n\n4848\n\n4949\n\n5050\n\n5151\n\n5252\n\n5353\n\n54\n54\n5555\n\n5656\n\n5757\n\n5858\n\n5959\n\n6060\n\n6161\n\n6262\n\n6363\n\n6464\n\n6565\n\n6666\n\n6767\n\n6868\n\n69\n69\n7070\n\n7171\n\n7272\n\n7373\n\n7474\n\n7575\n\n7676\n\n7777\n\n7878\n\n79\n79\n8080\n\n8181\n\n8282\n\n8383\n\n8484\n\n8585\n\n8686\n\n8787\n\n8888\n\n8989\n\n9090\n\n91\n91\n9292\n\n9393\n\n9494\n\n9595\n\n9696\n\n9797\n\n98\n98\n9999\n\n100100\n\n101101\n\n102102\n\n103103\n\n104104\n\n105\n105\n106106\n\n107107\n\n108108\n\n109109\n\n110110\n\n111\n111\n112112\n\n113113\n\n114114\n\n115115\n\n116116\n\n117117\n\n118\n118\n119119\n\n120120\n\n121121\n\n122122\n\n123\n123\n124\n124\n125125\n\n126126\n\n127127\n\n128128\n\n129129\n\n130130\n\n131131\n\n132132\n\n133133\n\n134\n134\n135135\n\n136136\n\n137137\n\n138\n138\n139139\n\n140\n140\n141141\n\n142142\n\n143143\n\n144144\n\n145145\n\n146146\n\n147147\n\n148148\n\n149149\n\n150150\n\n151151\n\n152152\n\n153153\n\n154154\n\n155155\n\n156156\n\n157157\n\n158158\n\n159159\n\n160160\n\n161161\n\n162162\n\n163163\n\n164164\n\n165165\n\n166166\n\n167167\n\n168168\n\n169\n169\n170170\n\n171171\n\n172172\n\n173173\n\n174174\n\n175175\n\n176176\n\n177177\n\n178\n178\n179179\n\n180180\n\n181181\n\n182182\n\n183183\n\n184184\n\n185185\n\n186186\n\n187187\n\n188188\n\n189189\n\n190190\n\n191\n191\n192192\n\n193193\n\n194194\n\n195195\n\n196196\n\n197197\n\n198\n198\n199199\n\n200200\n\n201201\n\n202202\n\n203\n203\n204204\n\n205205\n\n206206\n\n207207\n\n208208\n\n209209\n\n210210\n\n211211\n\n212212\n\n213213\n\n214214\n\n215215\n\n216216\n\n217217\n\n218218\n\n219219\n\n220220\n\n221221\n\n222222\n\n223223\n\n224224\n\n225225\n\n226226\n\n227227\n\n228228\n\n229229\n\n230230\n\n231231\n\n232232\n\n233233\n\n234234\n\n235235\n\n236236\n\n237237\n\n238238\n\n239239\n\n240240\n\n241241\n\n242242\n\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95814815f86a49d6822ef1754663b250"
      }
     },
     "metadata": {}
    }
   ]
  }
 ]
}
